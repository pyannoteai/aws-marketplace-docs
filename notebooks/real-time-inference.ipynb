{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy pyannoteAI Diarization Model Package from AWS Marketplace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Speaker Diarization API enables accurate segmentation of audio recordings by detecting and labeling individual speakers across time. Designed for seamless integration into transcription pipelines, media workflows, and audio analytics systems, it supports a wide range of formats including WAV, MP3, FLAC, and OGG. The service is language-agnostic and works across diverse audio sourcecalls, meetings, interviews, podcasts, and more. With built-in support for mono and stereo channels, varying sample rates, and flexible input options it can be deployed in batch or near-real-time use cases. Key features include automatic speaker count estimation, precise time-stamped speaker labeling, and detection of overlapping speech. Outputs are returned in structured JSON for easy integration with transcription engines, search indexes, or business intelligence tools. Whether you are enriching speech-to-text transcripts, analyzing call center performance, or processing long-form media, this API improves clarity, organization, and data usability.\n",
    "\n",
    "This sample notebook shows you how to deploy the **pyannoteAI Diarization Model** using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This reference notebook cannot run unless you make the suggested changes in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements that render correctly in the Jupyter interface. Open it from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that the IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions, and you have the authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. your AWS account has a **pyannoteAI Diarization Model** subscription. If so, skip the step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "    1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "    2. [Perform real-time inference](#B.-Perform-real-time-inference)\n",
    "    3. [Delete endpoint and model](#C.-Delete-endpoint-and-model)\n",
    "3. [Troubleshooting](#3.-Troubleshooting)\n",
    "4. [Questions](#4.-Questions)\n",
    "    \n",
    "We recommend using **ml.g4dn.xlarge** instance for real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page **pyannoteAI Diarization Model**.\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agree with EULA, pricing, and support terms. \n",
    "1. Once you click on the **Continue to configuration** button and choose a **region**, you will see a **Product ARN** displayed. This is the model package ARN that you need to specify while creating a deployable model using `boto3`. Copy the ARN corresponding to your region and specify it in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T17:30:41.123716Z",
     "start_time": "2024-03-03T17:30:41.100284Z"
    }
   },
   "outputs": [],
   "source": [
    "model_package_arn = \"arn:aws:sagemaker:{zone}:{account_id}:model-package/xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) if you want to understand how real-time inference with Amazon SageMaker works.\n",
    "\n",
    "NOTE: it's not streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pyannoteai-diarization\" # Write the endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify instance type\n",
    "real_time_inference_instance_type = \"ml.g4dn.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Note**: We recommend using ml.g4dn.xlarge instance for real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deployable model from the model package.\n",
    "model = ModelPackage(role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)\n",
    "\n",
    "# Wait until it prints \"!\" after \"----------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the endpoint has been created, you can perform real-time inference.\n",
    "\n",
    "If you get an error here, please see the [Troubleshooting](#6.-Troubleshooting).\n",
    "\n",
    "**WARNING!** \n",
    "\n",
    "**Remember to** [**Delete your endpoint and resources**](#D.-Delete-endpoint-and-model) whenever you finish your work with real-time inference to stop incurring your charges!\n",
    "\n",
    "For more information, please visit this [page](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-delete-resources.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "def invoke_endpoint(body):\n",
    "    results = runtime.invoke_endpoint(\n",
    "        EndpointName=model_name,\n",
    "        Body=json.dumps(body), \n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "\n",
    "    res = results['Body'].read().decode('utf-8')\n",
    "\n",
    "    return json.loads(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 Run diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files into memory\n",
    "with open(\"../example_files/marklex1min.wav\", \"rb\") as f:\n",
    "    marklex_audio_wav = f.read()\n",
    "\n",
    "diarization_result = invoke_endpoint({\n",
    "    \"audio\": base64.b64encode(marklex_audio_wav).decode('utf-8'),\n",
    "    \"num_speakers\": 2, # Optional, specify number of speakers if known beforehand\n",
    "})\n",
    "\n",
    "print(diarization_result[\"diarization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../example_files/marklex1min.mp3\", \"rb\") as f:\n",
    "    marklex_audio_mp3 = f.read()\n",
    "    \n",
    "diarization_result = invoke_endpoint({\n",
    "    \"audio\": base64.b64encode(marklex_audio_mp3).decode('utf-8'),\n",
    "    # automatically detect number of speakers\n",
    "})\n",
    "\n",
    "print(diarization_result[\"diarization\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Delete endpoint and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you no longer need the endpoint. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING!** \n",
    "\n",
    "**Remember to** [**Delete your endpoint and resources**](#D.-Delete-endpoint-and-model) whenever you finish your work with real-time inference to stop incurring your charges!\n",
    "\n",
    "For more information, please visit this [page](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-delete-resources.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cannot create already existing endpoint configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error occurs when the user interrupts the inference deployment and tries to rerun it. To restart the deployment, first delete the previously created configurations. You can find this command in the [Delete endpoint and model](#D.-Delete-endpoint-and-model) cell.\n",
    "\n",
    "Please wait for the deployment to complete. This process may take several minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResourceLimitExceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you receive an error due to the lack of a quota for your instance type, you can increase it by sending a request:\n",
    "1. Open the **Amazone SageMaker** [**Service Quotas**](https://console.aws.amazon.com/servicequotas/home/services/sagemaker/quotas) page.\n",
    "2. Check that you are in the correct AWS region where you want to increase the quota.\n",
    "3. Filter **Service quotas** by \"ml.g4dn.xlarge for endpoint usage\" for real-time inference.\n",
    "4. Select and click on the **Request increase at account-level** button.\n",
    "5. Enter the total amount you want the quota to be and click the **Request** button.\n",
    "6. Wait until AWS Support increases your quotas for this instance type.\n",
    "\n",
    "> **Note**: To speed up the processing of your request, please indicate in your correspondence with AWS Support that this type of instance is required for this product.\n",
    "\n",
    "For more information about requesting a quota increase, visit this [page](https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any questions about our product, feel free to email us at support@pyannote.ai."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "aws-marketplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
